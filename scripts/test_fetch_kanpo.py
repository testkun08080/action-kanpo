#!/usr/bin/env python3
"""
fetch_kanpo.py ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path

# å…ƒã®fetch_kanpo.pyã®å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«ä¸€éƒ¨ä¿®æ­£ï¼‰
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
from urllib.parse import urljoin, urlparse
import re


class KanpoFetcher:
    def __init__(self, test_mode=True):
        self.base_url = "https://www.kanpo.go.jp"
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"})
        self.test_mode = test_mode

    def get_today_date(self):
        """ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—"""
        return datetime.now().strftime("%Y-%m-%d")

    def create_date_folder(self, date_str):
        """æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ"""
        if self.test_mode:
            # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯ä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨
            base_folder = Path(tempfile.gettempdir()) / "kanpo_test"
        else:
            base_folder = Path("kanpo")

        folder_path = base_folder / date_str
        folder_path.mkdir(parents=True, exist_ok=True)
        return folder_path

    def fetch_main_page(self):
        """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
        try:
            print("ğŸŒ å®˜å ±ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")
            response = self.session.get(self.base_url + "/index.html", timeout=10)
            response.raise_for_status()
            print("âœ… ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ")
            return BeautifulSoup(response.content, "html.parser")
        except Exception as e:
            print(f"âŒ ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—: {e}")
            return None

    def find_today_kanpo_link(self, soup):
        """ä»Šæ—¥ã®å®˜å ±ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™"""
        print("ğŸ” ä»Šæ—¥ã®å®˜å ±ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢ä¸­...")
        today = datetime.now()
        yesterday = today - timedelta(days=1)

        # è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        patterns = [
            today.strftime("%Yå¹´%mæœˆ%dæ—¥"),
            today.strftime("%Y-%m-%d"),
            today.strftime("%mæœˆ%dæ—¥"),
            today.strftime("%m/%d"),
            yesterday.strftime("%Yå¹´%mæœˆ%dæ—¥"),  # æ˜¨æ—¥ã‚‚å«ã‚ã‚‹
            yesterday.strftime("%Y-%m-%d"),
            yesterday.strftime("%mæœˆ%dæ—¥"),
        ]

        print(f"ğŸ“… æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³: {patterns}")

        links = []
        for link in soup.find_all("a", href=True):
            link_text = link.get_text(strip=True)
            href = link.get("href", "")

            for pattern in patterns:
                if pattern in link_text or pattern in href:
                    full_url = urljoin(self.base_url, href)
                    links.append({"url": full_url, "text": link_text, "pattern_matched": pattern})
                    print(f"  âœ… ç™ºè¦‹: {link_text} (ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern})")
                    break

        if not links:
            print("âš ï¸  ä»Šæ—¥ãƒ»æ˜¨æ—¥ã®å®˜å ±ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("ğŸ’¡ åˆ©ç”¨å¯èƒ½ãªãƒªãƒ³ã‚¯ã®ä¾‹:")
            for i, link in enumerate(soup.find_all("a", href=True)[:10]):
                text = link.get_text(strip=True)
                if text and len(text) > 3:
                    print(f"    {i + 1}. {text}")

        return links

    def fetch_kanpo_page(self, kanpo_url):
        """å®˜å ±ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦PDFãƒªãƒ³ã‚¯ã‚’æŠ½å‡º"""
        print(f"ğŸ“– å®˜å ±ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†ä¸­: {kanpo_url}")
        try:
            response = self.session.get(kanpo_url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")

            pdf_links = []
            for link in soup.find_all("a", href=True):
                href = link["href"]
                if href.lower().endswith(".pdf"):
                    pdf_url = urljoin(kanpo_url, href)
                    pdf_name = link.get_text(strip=True) or os.path.basename(urlparse(href).path)
                    pdf_links.append({
                        "url": pdf_url,
                        "name": pdf_name,
                        "filename": os.path.basename(urlparse(href).path),
                    })
                    print(f"  ğŸ“„ PDFç™ºè¦‹: {pdf_name}")

            print(f"ğŸ“Š ã“ã®ãƒšãƒ¼ã‚¸ã§ {len(pdf_links)} å€‹ã®PDFã‚’ç™ºè¦‹")
            return pdf_links

        except Exception as e:
            print(f"âŒ å®˜å ±ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•— {kanpo_url}: {e}")
            return []

    def download_pdf(self, pdf_info, folder_path):
        """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            print(f"ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {pdf_info['name']}")

            if self.test_mode:
                # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®ã¿å–å¾—
                response = self.session.head(pdf_info["url"], timeout=10)
                response.raise_for_status()

                content_length = response.headers.get("Content-Length", "ä¸æ˜")
                content_type = response.headers.get("Content-Type", "ä¸æ˜")

                print(f"  âœ… ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªæˆåŠŸ")
                print(f"  ğŸ“Š ã‚µã‚¤ã‚º: {content_length} bytes")
                print(f"  ğŸ“‹ ã‚¿ã‚¤ãƒ—: {content_type}")

                # ãƒ†ã‚¹ãƒˆç”¨ã«ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                safe_filename = re.sub(r"[^\w\-_\.]", "_", pdf_info["filename"])
                if not safe_filename.endswith(".pdf"):
                    safe_filename += ".pdf"

                file_path = folder_path / safe_filename
                file_path.write_text(f"ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« - {pdf_info['name']}\nä½œæˆæ—¥æ™‚: {datetime.now()}")

                return True
            else:
                # å®Ÿéš›ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                response = self.session.get(pdf_info["url"], stream=True, timeout=30)
                response.raise_for_status()

                safe_filename = re.sub(r"[^\w\-_\.]", "_", pdf_info["filename"])
                if not safe_filename.endswith(".pdf"):
                    safe_filename += ".pdf"

                file_path = folder_path / safe_filename

                with open(file_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

                print(f"  âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {safe_filename}")
                return True

        except Exception as e:
            print(f"  âŒ PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•— {pdf_info['url']}: {e}")
            return False

    def create_readme(self, folder_path, pdf_list, date_str):
        """READMEãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        readme_path = folder_path / "README.md"

        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(f"# å®˜å ± {date_str}\n\n")
            f.write(f"å–å¾—æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if self.test_mode else 'ç„¡åŠ¹'}\n\n")
            f.write("## ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«\n\n")

            for pdf_info in pdf_list:
                f.write(f"- [{pdf_info['name']}]({pdf_info['filename']})\n")
                f.write(f"  - URL: {pdf_info['url']}\n")

        print(f"ğŸ“ README.md ã‚’ä½œæˆ: {readme_path}")

    def run(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        print("ğŸš€ å®˜å ±è‡ªå‹•å–å¾—ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
        print("=" * 60)

        # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’å–å¾—
        soup = self.fetch_main_page()
        if not soup:
            print("âŒ ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False

        # ä»Šæ—¥ã®å®˜å ±ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        today_links = self.find_today_kanpo_link(soup)
        if not today_links:
            print("âŒ ä»Šæ—¥ã®å®˜å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False

        print(f"\nğŸ“‹ å‡¦ç†å¯¾è±¡: {len(today_links)} å€‹ã®å®˜å ±ãƒªãƒ³ã‚¯")

        # æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        today_str = self.get_today_date()
        folder_path = self.create_date_folder(today_str)
        print(f"ğŸ“ ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€: {folder_path}")

        all_pdfs = []

        # å„å®˜å ±ãƒšãƒ¼ã‚¸ã‹ã‚‰PDFã‚’å–å¾—
        for i, link_info in enumerate(today_links):
            print(f"\n--- å®˜å ±ãƒšãƒ¼ã‚¸ {i + 1}/{len(today_links)} ---")
            print(f"ğŸ“– å‡¦ç†ä¸­: {link_info['text']}")

            pdf_links = self.fetch_kanpo_page(link_info["url"])

            for pdf_info in pdf_links:
                if self.download_pdf(pdf_info, folder_path):
                    all_pdfs.append(pdf_info)
                time.sleep(1)  # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›

        # çµæœã®ã¾ã¨ã‚
        print("\n" + "=" * 60)
        print("ğŸ“Š å®Ÿè¡Œçµæœ")
        print("=" * 60)

        if all_pdfs:
            self.create_readme(folder_path, all_pdfs, today_str)
            print(f"âœ… æˆåŠŸ: {len(all_pdfs)} å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸ")
            print(f"ğŸ“ ä¿å­˜å ´æ‰€: {folder_path}")

            # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
            print("\nğŸ“„ å–å¾—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:")
            for i, pdf in enumerate(all_pdfs, 1):
                print(f"  {i}. {pdf['name']}")

            return True
        else:
            print("âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False


def main():
    print("å®˜å ±å–å¾—ã‚·ã‚¹ãƒ†ãƒ  - ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ
    mode = input(
        "å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:\n"
        "1. ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®ã¿å–å¾—ã€æ¨å¥¨ï¼‰\n"
        "2. å®Ÿéš›ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n"
        "ç•ªå·ã‚’å…¥åŠ›: "
    ).strip()

    if mode == "2":
        test_mode = False
        print("âš ï¸  å®Ÿéš›ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™")
        confirm = input("æœ¬å½“ã«å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        if confirm != "y":
            print("ğŸ‘‹ å®Ÿè¡Œã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")
            return
    else:
        test_mode = True
        print("ğŸ’¡ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰ã§å®Ÿè¡Œã—ã¾ã™")

    print("\nğŸš€ ãƒ†ã‚¹ãƒˆé–‹å§‹...")

    fetcher = KanpoFetcher(test_mode=test_mode)
    success = fetcher.run()

    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        if test_mode:
            print("ğŸ’¡ å®Ÿéš›ã®é‹ç”¨ã§ã¯ GitHub Actions ãŒåŒæ§˜ã®å‡¦ç†ã‚’è‡ªå‹•å®Ÿè¡Œã—ã¾ã™")
        else:
            print("âœ… å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒæˆåŠŸã—ã¾ã—ãŸ")
    else:
        print("âš ï¸  å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        print("ğŸ”§ ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print("  - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š")
        print("  - å®˜å ±ã‚µã‚¤ãƒˆã®æ§‹é€ å¤‰æ›´")
        print("  - ä»Šæ—¥ãŒå®˜å ±ç™ºè¡Œæ—¥ã‹ï¼ˆåœŸæ—¥ç¥æ—¥ã¯é€šå¸¸ç™ºè¡Œã•ã‚Œã¾ã›ã‚“ï¼‰")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ãƒ†ã‚¹ãƒˆã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
